<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
    <title>inviso_lfm</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <link rel="stylesheet" href="css/main.css" type="text/css" media="screen" />
    <script src="js/main.js" type="text/javascript" charset="utf-8"></script>
</head>

<body>     
    <table width="100%" border='0' cellpadding='0' cellspacing='0' class='banner'>
        <tr>
            <td class="file-title"><span class="file-title-prefix">Module</span><br />inviso_lfm</td>
            <td align="right">

            </td>
        </tr>
    </table>
    <div id="bodyContent">
        <div id="content">
    
    <div class="description">
    <p>Implements an off-line logfile merger, merging binary trace-log files from several nodes together in chronological order. The logfile merger can also do pid-to-alias translations.</p>
    <p>The logfile merger is supposed to be called from the Erlang shell or a higher layer trace tool. For it to work, all logfiles and trace information files (containing the pid-alias associations) must be located in the file system accessible from this node and organized according to the API description.</p>
    <p>The logfile merger starts a process, the output process, which in its turn starts one reader process for every node it shall merge logfiles from. Note that the reason for a process for each node is not remote communication, the logfile merger is an off-line utility, it is to sort the logfile entries in chronological order.</p>
    <p>The logfile merger can be customized both when it comes to the implementation of the reader processes and the output the output process shall generate for every logfile entry.</p>
  </div>
    

    
    
    <div class="sectiontitle">Contents</div>
    <ul>
        
        <li><a href="#">Writing Your Own Reader Process</a></li>
        
    </ul>
    

    
    
    <div class="sectiontitle">Functions</div>
    <ul>
        
        <li><a href="#mergeFilesOutFilegt">merge(Files, OutFile) -&gt;</a></li>
        
    </ul>
    

     
    <div class="sectiontitle">Writing Your Own Reader Process</div>
    
    <div class="description">
        
    <title>Writing Your Own Reader Process</title>
    <p>Writing a reader process is not that difficult. It must:</p>
    <list type="bulleted">
      <item>Export an init-like function accepting two arguments, pid of the output process and the <tt>LogFiles</tt> component. <tt>LogFiles</tt> is actually only used by the reader processes, making it possible to redefine <tt>LogFiles</tt> if implementing an own reader process.</item>
      <item>Respond to <tt>{get_next_entry, OutputPid}</tt> messages with <tt>{next_entry, self(), PidMappings, NowTimeStamp, Term}</tt> or <tt>{next_entry, self(), {error,Reason}}</tt>.</item>
      <item>Terminate normally when no more log entries are available.</item>
      <item>Terminate on an incoming EXIT-signal from <tt>OutputPid</tt>.</item>
    </list>
    <p>The reader process must of course understand the format of a logfile written by the runtime component.</p>
  
    </div>
    
    
	<div class="sectiontitle">Exports</div>
		
            <div class="method">
                <div class="title">
                    <a name="mergeFilesOutFilegt"></a><b>merge(Files, OutFile) -&gt;<br/>merge(Files, WorkHFun, InitHandlerData) -&gt;<br/>merge(Files, BeginHFun, WorkHFun, EndHFun, InitHandlerData) -&gt; {ok, Count} | {error, Reason}</b>
                </div>

								
                <div class="func_types">
									Types:
									<p>
                  
        <b>Files = [FileDescription]</b><br/>
        <b>&nbsp;FileDescription = FileSet | {reader,RMod,RFunc,FileSet}</b><br/>
        <b>&nbsp;&nbsp;FileSet = {Node,LogFiles} | {Node,[LogFiles]}</b><br/>
        <b>&nbsp;&nbsp;&nbsp;Node = atom()</b><br/>
        <b>&nbsp;&nbsp;&nbsp;LogFiles = [{trace_log,[FileName]}] | [{trace_log,[FileName]},{ti_log,TiFileSpec}]</b><br/>
        <b>&nbsp;&nbsp;&nbsp;&nbsp;TiFileSpec = [string()] - a list of one string.</b><br/>
        <b>&nbsp;&nbsp;&nbsp;&nbsp;FileName = string()</b><br/>
        <b>&nbsp;&nbsp;RMod = RFunc = atom()</b><br/>
        <b>OutFile = string()</b><br/>
        <b>BeginHFun = fun(InitHandlerData) -&gt; {ok, NewHandlerData} | {error, Reason}</b><br/>
        <b>WorkHFun = fun(Node, LogEntry, PidMappings, HandlerData) -&gt; {ok, NewHandlerData}</b><br/>
        <b>&nbsp;LogEntry = tuple()</b><br/>
        <b>&nbsp;PidMappings = term()</b><br/>
        <b>EndHFun = fun(HandlerData) -&gt; ok | {error, Reason}</b><br/>
        <b>Count = int()</b><br/>
        <b>Reason = term()</b><br/>
      
									</p>
                </div>
                
                
                <div class="description">
                  
        <p>Merges the logfiles in <tt>Files</tt> together into one file in chronological order. The logfile merger consists of an output process and one or several reader processes.</p>
        <p>Returns <tt>{ok, Count}</tt> where <tt>Count</tt> is the total number of log entries processed, if successful.</p>
        <p>When specifying <tt>LogFiles</tt>, currently the standard reader-process only supports:</p>
        <list type="bulleted">
          <item>one single file</item>
          <item>a list of wraplog files, following the naming convention <tt><![CDATA[<Prefix><Nr><Suffix>]]></tt>.</item>
        </list>
        <p>Note that (when using the standard reader process) it is possible to give a list of <tt>LogFiles</tt>. The list must be sorted starting with the oldest. This will cause several trace-logs (from the same node) to be merged together in the same <tt>OutFile</tt>. The reader process will simply start reading the next file (or wrapset) when the previous is done.</p>
        <p><tt>FileDescription == {reader,RMod,RFunc,FileSet}</tt> indicates that <tt>spawn(RMod, RFunc, [OutputPid,LogFiles])</tt> shall create a reader process.</p>
        <p>The output process is customized with <tt>BeginHFun</tt>, <tt>WorkHFun</tt> and <tt>EndHFun</tt>. If using <tt>merge/2</tt> a default output process configuration is used, basically creating a text file and writing the output line by line. <tt>BeginHFun</tt> is called once before requesting log entries from the reader processes. <tt>WorkHFun</tt> is called for every log entry (trace message) <tt>LogEntry</tt>. Here the log entry typically gets written to the output. <tt>PidMappings</tt> is the translations produced by the reader process. <tt>EndHFun</tt> is called when all reader processes have terminated.</p>
        <p>Currently the standard reader can only handle one ti-file (per <tt>LogFiles</tt>). The current inviso meta tracer is further not capable of wrapping ti-files. (This also because a wrapped ti-log will most likely be worthless since alias associations done in the beginning are erased but still used in the trace-log).</p>
        <p>The standard reader process is implemented in the module <tt>inviso_lfm_tpreader</tt> (trace port reader). It understands Erlang linked in trace-port driver generated trace-logs and <tt>inviso_rt_meta</tt> generated trace information files.</p>
      
                </div>
                

            </div>
      


    
</div>
    </div>
  </body>
</html>    